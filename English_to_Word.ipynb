{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":915334,"sourceType":"datasetVersion","datasetId":492138}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-01T09:57:38.667592Z","iopub.execute_input":"2025-06-01T09:57:38.668223Z","iopub.status.idle":"2025-06-01T09:57:42.734284Z","shell.execute_reply.started":"2025-06-01T09:57:38.668190Z","shell.execute_reply":"2025-06-01T09:57:42.733442Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\n\ndf = pd.read_csv(\"/kaggle/input/english-to-hindi-parallel-dataset/newdata.csv\")  # Replace with actual path\ndf = df.dropna(subset=['english_sentence', 'hindi_sentence'])\n\ndf['eng'] = df['english_sentence'].astype(str)\ndf['hindi'] = df['hindi_sentence'].astype(str)\n\neng_sentences = df['eng'].tolist()\nhin_sentences = df['hindi'].tolist()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T09:57:42.735939Z","iopub.execute_input":"2025-06-01T09:57:42.736650Z","iopub.status.idle":"2025-06-01T09:57:45.163922Z","shell.execute_reply.started":"2025-06-01T09:57:42.736627Z","shell.execute_reply":"2025-06-01T09:57:45.163287Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"def tokenize(sentence):\n    return sentence.lower().strip().split()\nfrom collections import Counter\n\ndef build_vocab(sentences, min_freq=1):\n    counter = Counter()\n    for sentence in sentences:\n        counter.update(tokenize(sentence))\n    \n    vocab = {'<pad>': 0, '<sos>': 1, '<eos>': 2, '<unk>': 3}\n    for word, freq in counter.items():\n        if freq >= min_freq:\n            vocab[word] = len(vocab)\n    return vocab\n\neng_vocab = build_vocab(eng_sentences)\nhin_vocab = build_vocab(hin_sentences)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T09:57:45.164541Z","iopub.execute_input":"2025-06-01T09:57:45.164746Z","iopub.status.idle":"2025-06-01T09:57:46.828313Z","shell.execute_reply.started":"2025-06-01T09:57:45.164729Z","shell.execute_reply":"2025-06-01T09:57:46.827726Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"class TranslationData(Dataset):\n    def __init__(self,src,tgt,src_vocab,tgt_vocab):\n        self.src = src\n        self.tgt = tgt\n        self.src_vocab = src_vocab\n        self.tgt_vocab = tgt_vocab\n\n    def __len__(self):\n        return len(self.src)\n\n    def __getitem__(self,indx):\n        src_tokens = self.encode(self.src[indx],self.src_vocab)\n        tgt_tokens = self.encode(self.tgt[indx],self.tgt_vocab)\n        return torch.tensor(src_tokens),torch.tensor(tgt_tokens)\n\n    def encode(self,sentence,vocab):\n        tokens = sentence.lower().split()\n        return[vocab['<sos>']]+[vocab.get(tok,vocab['<unk>']) for tok in tokens] + [vocab['<eos>']]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T09:57:46.828958Z","iopub.execute_input":"2025-06-01T09:57:46.829144Z","iopub.status.idle":"2025-06-01T09:57:46.844249Z","shell.execute_reply.started":"2025-06-01T09:57:46.829128Z","shell.execute_reply":"2025-06-01T09:57:46.843559Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"from torch.nn.utils.rnn import pad_sequence\n\ndef collate_fn(batch):\n    src_batch, tgt_batch = zip(*batch)\n\n    src_lengths = torch.tensor([len(seq) for seq in src_batch])\n    tgt_lengths = torch.tensor([len(seq) for seq in tgt_batch])\n\n    src_padded = pad_sequence(src_batch, batch_first=True, padding_value=eng_vocab['<pad>'])\n    tgt_padded = pad_sequence(tgt_batch, batch_first=True, padding_value=hin_vocab['<pad>'])\n\n    return src_padded, tgt_padded, src_lengths, tgt_lengths","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T09:57:46.846394Z","iopub.execute_input":"2025-06-01T09:57:46.846594Z","iopub.status.idle":"2025-06-01T09:57:46.859003Z","shell.execute_reply.started":"2025-06-01T09:57:46.846578Z","shell.execute_reply":"2025-06-01T09:57:46.858394Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\ntrain_dataset = TranslationData(eng_sentences, hin_sentences, eng_vocab, hin_vocab)\n\ntrain_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, collate_fn=collate_fn)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T09:57:46.859939Z","iopub.execute_input":"2025-06-01T09:57:46.860444Z","iopub.status.idle":"2025-06-01T09:57:46.877083Z","shell.execute_reply.started":"2025-06-01T09:57:46.860419Z","shell.execute_reply":"2025-06-01T09:57:46.876388Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"for src, tgt, src_mask, tgt_mask in train_loader:\n    print(\"Source shape:\", src.shape)\n    print(\"Target shape:\", tgt.shape)\n    print(\"Source mask shape:\", src_mask.shape)\n    print(\"Target mask shape:\", tgt_mask.shape)\n    break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T09:57:46.877845Z","iopub.execute_input":"2025-06-01T09:57:46.878098Z","iopub.status.idle":"2025-06-01T09:57:46.955465Z","shell.execute_reply.started":"2025-06-01T09:57:46.878080Z","shell.execute_reply":"2025-06-01T09:57:46.954862Z"}},"outputs":[{"name":"stdout","text":"Source shape: torch.Size([8, 39])\nTarget shape: torch.Size([8, 38])\nSource mask shape: torch.Size([8])\nTarget mask shape: torch.Size([8])\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"for src, tgt, *_ in train_loader:\n    print(\"Input batch shape:\", src.shape)\n    break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T09:57:46.956245Z","iopub.execute_input":"2025-06-01T09:57:46.956474Z","iopub.status.idle":"2025-06-01T09:57:46.974287Z","shell.execute_reply.started":"2025-06-01T09:57:46.956452Z","shell.execute_reply":"2025-06-01T09:57:46.973710Z"}},"outputs":[{"name":"stdout","text":"Input batch shape: torch.Size([8, 29])\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"class Encoder(nn.Module):\n    def __init__(self,input_dim,hidden_dim,num_layers=2):\n        super().__init__()\n        self.embedding = nn.Embedding(input_dim,hidden_dim)\n        self.lstm = nn.LSTM(hidden_dim,1024,num_layers,bias=True,proj_size=hidden_dim,batch_first=True)\n        self.input_dim = input_dim\n        self.hidden_dim = hidden_dim\n        self.nums_layers = num_layers\n    def forward(self,x):\n        embedding = self.embedding(x)\n        output, (hidden,cell) = self.lstm(embedding)\n        return output,hidden,cell","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T13:37:41.250123Z","iopub.execute_input":"2025-06-01T13:37:41.250790Z","iopub.status.idle":"2025-06-01T13:37:41.255449Z","shell.execute_reply.started":"2025-06-01T13:37:41.250765Z","shell.execute_reply":"2025-06-01T13:37:41.254763Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"print(\"src batch size:\", src.shape[1])\nprint(\"tgt batch size:\", tgt.shape[1])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T09:57:46.981105Z","iopub.execute_input":"2025-06-01T09:57:46.981785Z","iopub.status.idle":"2025-06-01T09:57:46.993763Z","shell.execute_reply.started":"2025-06-01T09:57:46.981767Z","shell.execute_reply":"2025-06-01T09:57:46.993112Z"}},"outputs":[{"name":"stdout","text":"src batch size: 29\ntgt batch size: 32\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"class Decoder(nn.Module):\n    def __init__(self,output_dim, hidden_dim, num_layers=2):\n        super().__init__()\n        self.embedding = nn.Embedding(output_dim,hidden_dim)\n        self.lstm = nn.LSTM(hidden_dim,1024,num_layers,bias=True,proj_size=hidden_dim,batch_first=True)\n        self.fc = nn.Linear(hidden_dim,output_dim)\n        self.num_layers = num_layers\n        self.hidden_dim = hidden_dim\n\n    def forward(self,x,hidden,cell):\n        embedding = self.embedding(x)\n        outputs,(hidden,cell) = self.lstm(embedding, (hidden,cell))\n        predictions = self.fc(outputs)\n        return predictions, hidden,cell","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T13:37:43.313377Z","iopub.execute_input":"2025-06-01T13:37:43.313909Z","iopub.status.idle":"2025-06-01T13:37:43.318640Z","shell.execute_reply.started":"2025-06-01T13:37:43.313886Z","shell.execute_reply":"2025-06-01T13:37:43.318072Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"import torch.optim as optim\nINPUT_DIM = len(eng_vocab)\nOUTPUT_DIM = len(hin_vocab)\nHIDDEN_DIM = 512\nEPOCHS = 5\ndevice = 'cuda'\n\nclass seq2seq(nn.Module):\n    def __init__(self,encoder,decoder):\n        super().__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n\n    def forward(self,src,tgt):\n        output,hidden,cell = self.encoder(src)\n        prediction ,hidden,cell = self.decoder(tgt,hidden,cell)\n        return prediction\n\nencoder = Encoder(INPUT_DIM, HIDDEN_DIM)\ndecoder = Decoder(OUTPUT_DIM, HIDDEN_DIM)\nmodel = seq2seq(encoder,decoder).to(device)\ncriterion = nn.CrossEntropyLoss(ignore_index=hin_vocab['<pad>'])\noptimizer = optim.Adam(model.parameters(), lr=1e-4)\nfor epoch in range(EPOCHS):\n    model.train()\n    epoch_loss = 0\n\n    for src, tgt, _, _ in train_loader:\n        src = src.to(device)\n        tgt = tgt.to(device)\n\n        # Create decoder input for teacher forcing\n        tgt_input = torch.zeros_like(tgt)\n        tgt_input[:, 1:] = tgt[:, :-1]\n        tgt_input[:, 0] = hin_vocab['<sos>']  # Assuming <sos> is at index 1\n\n        optimizer.zero_grad()\n        output = model(src, tgt_input)  # output shape: [batch_size, seq_len, output_dim]\n\n        # Flatten output and target for loss\n        output = output.view(-1, OUTPUT_DIM)\n        tgt = tgt.view(-1)\n\n        loss = criterion(output, tgt)\n        loss.backward()\n        optimizer.step()\n\n        epoch_loss += loss.item()\n\n    print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {epoch_loss:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ndef evaluate(model, src, max_len=50):\n    model.eval()\n    with torch.no_grad():\n        src = src.to(DEVICE)\n\n        # Encode input\n        enc_outputs, hidden, cell = model.encoder(src)\n\n        batch_size = src.size(0)\n        tgt_vocab_size = len(hin_vocab)\n        outputs = []\n\n        # Initialize decoder input with <sos>\n        input_tok = torch.full((batch_size, 1), hin_vocab['<sos>'], dtype=torch.long, device=DEVICE)\n\n        for _ in range(max_len):\n            output, hidden, cell = model.decoder(input_tok, hidden, cell)\n            pred = output[:, -1, :].argmax(-1, keepdim=True)  # get last predicted token\n            outputs.append(pred)\n            input_tok = pred  # use previous prediction as next input\n\n        # Concatenate predictions: shape [batch_size, seq_len]\n        outputs = torch.cat(outputs, dim=1)\n    return outputs\n\ndef decode_sequence(token_ids, vocab):\n    inv_vocab = {v: k for k, v in vocab.items()}\n    return ' '.join([inv_vocab.get(tok.item(), '<unk>') for tok in token_ids if tok.item() != vocab['<eos>']])\nbatch_iterator = iter(train_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T13:37:31.100329Z","iopub.status.idle":"2025-06-01T13:37:31.100614Z","shell.execute_reply.started":"2025-06-01T13:37:31.100483Z","shell.execute_reply":"2025-06-01T13:37:31.100495Z"}},"outputs":[],"execution_count":null}]}